{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习\n",
    "\n",
    "1.k近邻（kNN）\n",
    "  \n",
    "  用于：分类 from sklearn.neighbors import KNeighborsClassifier\n",
    "  \n",
    "         主要参数：n_neighbors 设置邻居个数 邻居个数越多，决策边界越平滑，对应更简单的模型。\n",
    "       \n",
    "  用于：回归 from sklearn.neighbors import KNeighborsRegressor\n",
    "            \n",
    "         主要参数：n_neighbors\n",
    "  \n",
    "  总结：使用较小的邻居个数（比如3个或5个）往往可以得到比较好的结果\n",
    "      对数据进行预处理很重要\n",
    "      对于有很多特征的数据集往往效果不好\n",
    "      预测速度慢\n",
    "      实践中往往不会用到\n",
    "        \n",
    "2.线性模型\n",
    "\n",
    "    用于：分类 \n",
    "        \n",
    "        1.Logistic Regression from sklearn.linear_model import LogisticRegression\n",
    "       &\n",
    "        2.线性支持向量机 from sklearn.svm impoet LinearSVC\n",
    "        \n",
    "          主要参数：\n",
    "                C 决定正则化强度的权衡参数，C值越大，正则化越弱。较小的C值可以让算法尽量适应“大多数”数据点，\n",
    "                较大的C值更强调每个数据点都分类正确额的重要性。\n",
    "                \n",
    "                penalty 默认使用L2正则化，可选penalty=\"l1\"。影响正则化，影响模型使用所有特征还是特征子集。\n",
    "                \n",
    "    用于：回归\n",
    "    \n",
    "        1.线性回归（普通最小二乘法） from sklearn.linear_model import linearRegression\n",
    "        \n",
    "         主要参数：没有参数，无法控制模型的复杂度\n",
    "        \n",
    "        2.岭回归 from sklearn.linear_model import Ridge\n",
    "        \n",
    "         主要参数：alpha 默认参数alpha=1.0。L2正则化，增大alpha会使得系数更加趋向于0，从而而降低训练集性能，很可能会提高泛化性能。\n",
    "    \n",
    "        3.lasso from sklearn.linear_model import lasso\n",
    "        \n",
    "         主要参数：alpha 默认参数alpha=1.0。L1正则化，控制系数趋向于0的强度。\n",
    "                 \n",
    "               max_iter 运行迭代的最大次数。减小alpha的同时，需要增加max_iter。\n",
    "               \n",
    "        在实践中，一般首选岭回归。如果只有几个特征是重要的，选择lasso可能更好。\n",
    "        \n",
    "    总结：训练速度非常快，预测速度也很快；\n",
    "        可以推广到非常大的数据集，对稀疏数据也很有效；\n",
    "        solver=\"sag\"选项在处理大型数据时，比默认值更快；\n",
    "        斜率（权重、系数）保存在coef_属性中，偏移（截距）保存在intercept_属性中。\n",
    "        \n",
    "3.朴素贝叶斯分类器\n",
    "   \n",
    "    用于：分类\n",
    "        GaussianNB应用于任意连续数据。\n",
    "        BernoulliNB假定输入数据为二分类数据。主要用于文本数据分类。\n",
    "        MultinomialNB假定输入数据为计数数据。主要用于文本数据分类。\n",
    "        \n",
    "    主要参数：MultinomialNB和BernoulliNB只有一个参数alpha，用于控制模型复杂度。alpha越大，模型复杂度越低。\n",
    "    \n",
    "    总结：对高维稀疏数据效果很好，对参数的鲁棒性较好。训练和预测速度快。\n",
    "    \n",
    "4.决策树\n",
    "\n",
    "    用于：分类 from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    主要参数：random_state 在内部解决平局问题\n",
    "          \n",
    "           max_depth 限制树的深度，减少过拟合\n",
    "           \n",
    "    总结：可以利用tree模块的export_graphviz函数将树可视化。\n",
    "        feature_importances_特征重要性，介于0到1之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"maglinant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
